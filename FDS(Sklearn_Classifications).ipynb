{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDS(Sklearn-Classifications).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rakesh4334/ChandraRakesh.github.io/blob/main/FDS(Sklearn_Classifications).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IDYe9URSsBQ"
      },
      "source": [
        "***\n",
        "**LOADING DATASET**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDN7ijbleYG4",
        "outputId": "90b8f46f-8768-473e-8672-233b5b5a4e7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU8PrK3kdBFk"
      },
      "source": [
        "import pandas as pd\n",
        "data = '/content/drive/MyDrive/IMDB Dataset.csv'\n",
        "df = pd.read_csv(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDPkf8SwdIws"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()#converting a collection of text into token counts\n",
        "review = cv.fit_transform(df['review']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Hw42U0SnV9"
      },
      "source": [
        "***\n",
        "**TOKENIZE THE DATASET**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vkchTt5rF6m"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "def stemmer_tokenize(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "#wont work for CJK as they dont have a concept of space seperation "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc-Zdz6dS7Md"
      },
      "source": [
        "***\n",
        "**VECTORIZE DATASET**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7VOgqPEsT7a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(strip_accents = None, lowercase = False, use_idf=True, smooth_idf=True, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aSmPDXXtRpz"
      },
      "source": [
        "Y = df.sentiment.values\n",
        "X = tfidf.fit_transform(df.review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP69kDMGTE-5"
      },
      "source": [
        "***\n",
        "**BUILDING THE CLASSIFIER**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXv3Solvtbz1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, x_test, Y_train, y_test = train_test_split(X,Y,random_state = 1, test_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-KCBUjJt1Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf605b0e-6486-4b56-99e4-99af98e22dcc"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV \n",
        "model= LogisticRegressionCV(cv = 5, scoring= 'accuracy', n_jobs= 3, verbose=3, max_iter=100)\n",
        "model.fit(X_train,Y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.6min\n",
            "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:  1.6min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=3, penalty='l2',\n",
              "                     random_state=None, refit=True, scoring='accuracy',\n",
              "                     solver='lbfgs', tol=0.0001, verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRySVajnVUVK"
      },
      "source": [
        "***\n",
        "**SAVING THE MODEL**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMh5sAFVa6X"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/saved models/FDS_CLASSIFIER.sav','wb') as saved_model:\n",
        "    pickle.dump(model, saved_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcnYdVRWwHoK"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/saved models/FDS_CLASSIFIER.sav','rb') as saved_model:\n",
        "     emotion_predictor = pickle.load(saved_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5fL2g2jZQCx"
      },
      "source": [
        "***\n",
        "**EVALUATION OF THE CLASSFIER**\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbCWxJ9rl6o0",
        "outputId": "d77c68b8-8a98-468d-c6c3-f5d286a0bf00"
      },
      "source": [
        "emotion_predictor.score(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8883428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}